{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e91c0a2a-60d2-4df1-9bf4-4b99bb506bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part1\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part2\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part3\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part4\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part5\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part6\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part7\n",
      "Merged: globalARcatalog_ERA5_1940-2024_v4.0.nc.part8\n",
      "\n",
      "‚úÖ Successfully merged into: C:\\Users\\vedik\\OneDrive\\Desktop\\minor project\\detection\\globalARcatalog_ERA5_1940-2024_v4.0.nc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Folder where your parts are stored\n",
    "folder = r\"C:\\Users\\vedik\\OneDrive\\Desktop\\minor project\\detection\"\n",
    "\n",
    "# Base output filename\n",
    "output_file = os.path.join(folder, \"globalARcatalog_ERA5_1940-2024_v4.0.nc\")\n",
    "\n",
    "# Automatically find and sort part files\n",
    "part_files = sorted([\n",
    "    os.path.join(folder, f) for f in os.listdir(folder)\n",
    "    if f.startswith(\"globalARcatalog_ERA5_1940-2024_v4.0.nc.part\")\n",
    "])\n",
    "\n",
    "# Merge parts\n",
    "with open(output_file, \"wb\") as outfile:\n",
    "    for part in part_files:\n",
    "        with open(part, \"rb\") as infile:\n",
    "            data = infile.read()\n",
    "            outfile.write(data)\n",
    "        print(f\"Merged: {os.path.basename(part)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully merged into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67a06112-d6af-4ea2-baec-91844198629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AR detected near Chennai at ~2015-12-05T00:00:00 UTC\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import dask\n",
    "NCFILE   = \"globalARcatalog_ERA5_1940-2024_v4.0.nc\"\n",
    "_ds      = xr.open_dataset(NCFILE,  engine=\"netcdf4\")\n",
    "_shapemap = _ds[\"shapemap\"].squeeze(drop=True)  \n",
    "\n",
    "def ar_near(lat, lon, local_time_str, radius_km=50):\n",
    "    \"\"\"\n",
    "    Check ¬±6H √ó ¬±radius_km if any pixel saw an AR.\n",
    "    local_time_str in 'YYYY-MM-DD HH:MM' IST.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ist = pd.to_datetime(local_time_str).tz_localize(\"Asia/Kolkata\")\n",
    "    utc = ist.tz_convert(\"UTC\")\n",
    "\n",
    "  \n",
    "    hours = utc.floor(\"6h\")\n",
    "    times = [hours, hours + pd.Timedelta(hours=6)]\n",
    "\n",
    "    \n",
    "    deg_lat = radius_km / 111.0\n",
    "    deg_lon = radius_km / (111.0 * math.cos(math.radians(lat)))\n",
    "\n",
    "   \n",
    "    for t in times:\n",
    "        \n",
    "        t6 = t.strftime(\"%Y-%m-%dT%H:00:00\")\n",
    "        try:\n",
    "            sub = _shapemap.sel(time=t6, method=\"nearest\")\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        lat0, lat1 = lat - deg_lat, lat + deg_lat\n",
    "        lon0, lon1 = (lon % 360) - deg_lon, (lon % 360) + deg_lon\n",
    "\n",
    "        box = sub.sel(\n",
    "            lat=slice(lat1, lat0),         \n",
    "            lon=slice(lon0 % 360, lon1 % 360)\n",
    "        )\n",
    "\n",
    "        arr = box.data\n",
    "        if np.isfinite(arr).any():\n",
    "            return True, t6\n",
    "\n",
    "    return False, None\n",
    "\n",
    "\n",
    "found, when = ar_near(54.50    , -2.90   , \"2015-12-05  06:00\", radius_km=50)\n",
    "if found:\n",
    "    print(f\"‚úÖ AR detected near Chennai at ~{when} UTC\")\n",
    "else:\n",
    "    print(\"‚ùå No AR found in that window.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbbe3629-5b8f-4d95-b91b-965f313b45a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è Gujarat: 1 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Maharashtra: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Dadra and Nagar Haveli: 1 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Karnataka: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Telangana: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Andhra Pradesh: 4 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Goa: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Kerala: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Tamil Nadu: 5 AR duration events\n",
      "   - Start: 2013-06-10 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Rajasthan: 2 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Jammu and Kashmir: 3 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Himachal Pradesh: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Punjab: 2 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Uttarakhand: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Haryana: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Uttar Pradesh: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è NCT of Delhi: 2 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Bihar: 3 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Madhya Pradesh: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Jharkhand: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è West Bengal: 2 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Chhattisgarh: 4 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Odisha: 3 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "üó∫Ô∏è Chandigarh: 1 AR duration events\n",
      "   - Start: 2013-06-15 18:00 | Duration: 18 hrs\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load shapefile for Indian states\n",
    "states_gdf = gpd.read_file(\"india_states.shp\", layer=\"gadm41_IND_1\")  # Make sure the CRS is in degrees (EPSG:4326)\n",
    "states_gdf = states_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Load dataset\n",
    "NCFILE   = \"globalARcatalog_ERA5_1940-2024_v4.0.nc\"\n",
    "_ds      = xr.open_dataset(NCFILE, engine=\"netcdf4\")\n",
    "_shapemap = _ds[\"shapemap\"].squeeze(drop=True)\n",
    "\n",
    "def ar_events_statewise_with_duration(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Detect AR events in India for the given date range.\n",
    "    Return dictionary of state: list of event times (rounded to 6-hourly bins).\n",
    "    \"\"\"\n",
    "\n",
    "    # Bounding box for India (approximate)\n",
    "    lat_min, lat_max = 6.0, 37.0\n",
    "    lon_min, lon_max = 68.0, 97.5\n",
    "    lon_min360, lon_max360 = lon_min % 360, lon_max % 360\n",
    "\n",
    "    state_events = {}\n",
    "\n",
    "    for t in _shapemap.time.values:\n",
    "        dt = pd.to_datetime(str(t))\n",
    "        if not (start_date <= dt <= end_date):\n",
    "            continue\n",
    "\n",
    "        sub = _shapemap.sel(time=t)\n",
    "        box = sub.sel(\n",
    "            lat=slice(lat_max, lat_min),\n",
    "            lon=slice(lon_min360, lon_max360)\n",
    "        )\n",
    "\n",
    "        arr = box.data\n",
    "        if not np.isfinite(arr).any():\n",
    "            continue\n",
    "\n",
    "        lat_vals = box.lat.values\n",
    "        lon_vals = box.lon.values\n",
    "        mask = np.isfinite(arr)\n",
    "\n",
    "        for i, j in zip(*np.where(mask)):\n",
    "            lat = float(lat_vals[i])\n",
    "            lon = float(lon_vals[j])\n",
    "            lon_deg = lon if lon <= 180 else lon - 360  # convert from 0‚Äì360 to -180‚Äì180\n",
    "\n",
    "            point = Point(lon_deg, lat)\n",
    "            match = states_gdf[states_gdf.contains(point)]\n",
    "\n",
    "            if not match.empty:\n",
    "                state_name = match.iloc[0][\"NAME_1\"]  # or your state name column\n",
    "                if state_name not in state_events:\n",
    "                    state_events[state_name] = []\n",
    "                state_events[state_name].append(dt)\n",
    "\n",
    "    return state_events\n",
    "\n",
    "def compute_event_durations(state_events):\n",
    "    \"\"\"\n",
    "    From list of timestamps per state, compute grouped durations (6‚Äì72 hrs).\n",
    "    Returns dictionary of state -> list of (start_time, duration_hours)\n",
    "    \"\"\"\n",
    "    duration_summary = {}\n",
    "    for state, times in state_events.items():\n",
    "        times_sorted = sorted(pd.to_datetime(times))\n",
    "        durations = []\n",
    "    \n",
    "        current_start = times_sorted[0]\n",
    "        prev = current_start\n",
    "        hours = 6\n",
    "    \n",
    "        for t in times_sorted[1:]:\n",
    "            delta = (t - prev).total_seconds() / 3600\n",
    "    \n",
    "            if delta == 6:\n",
    "                hours += 6\n",
    "            else:\n",
    "                if hours >= 12:  # ‚úÖ Minimum duration: 24 hrs\n",
    "                    durations.append((current_start, hours))\n",
    "                current_start = t\n",
    "                hours = 6\n",
    "            prev = t\n",
    "    \n",
    "        # Check final group\n",
    "        if hours >= 12:\n",
    "            durations.append((current_start, hours))\n",
    "    \n",
    "        duration_summary[state] = durations\n",
    "\n",
    "    return duration_summary  \n",
    "\n",
    "    print(\"‚úî Finished detecting statewise AR events.\")\n",
    "    print(\"States found with ARs:\", list(statewise_events.keys()))\n",
    "    print(\"‚úî Finished computing durations.\")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "start_date = pd.to_datetime(\"2013-06-10\")\n",
    "end_date = pd.to_datetime(\"2013-06-16 23:59\")\n",
    "\n",
    "# Detect AR events\n",
    "statewise_events = ar_events_statewise_with_duration(start_date, end_date)\n",
    "statewise_durations = compute_event_durations(statewise_events)\n",
    "\n",
    "# Print summary\n",
    "for state, events in statewise_durations.items():\n",
    "    print(f\"üó∫Ô∏è {state}: {len(events)} AR duration events\")\n",
    "    for (start, dur) in events:\n",
    "        if dur <= 72:\n",
    "            print(f\"   - Start: {start.strftime('%Y-%m-%d %H:%M')} | Duration: {dur} hrs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d20bee-4539-4314-b8f9-ad1e832fdb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóª Uttarakhand: 4 AR duration events\n",
      "   - Start: 2013-06-16 00:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 06:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-16 12:00 | Duration: 12 hrs\n",
      "   - Start: 2013-06-17 12:00 | Duration: 12 hrs\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load shapefile for Indian states\n",
    "states_gdf = gpd.read_file(\"india_states.shp\", layer=\"gadm41_IND_1\")\n",
    "states_gdf = states_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Load dataset\n",
    "NCFILE = \"globalARcatalog_ERA5_1940-2024_v4.0.nc\"\n",
    "_ds = xr.open_dataset(NCFILE, engine=\"netcdf4\")\n",
    "_shapemap = _ds[\"shapemap\"].squeeze(drop=True)\n",
    "\n",
    "def ar_events_uttarakhand_only(start_date, end_date):\n",
    "    lat_min, lat_max = 6.0, 37.0\n",
    "    lon_min, lon_max = 68.0, 97.5\n",
    "    lon_min360, lon_max360 = lon_min % 360, lon_max % 360\n",
    "\n",
    "    state_events = []\n",
    "\n",
    "    for t in _shapemap.time.values:\n",
    "        dt = pd.to_datetime(str(t))\n",
    "        if not (start_date <= dt <= end_date):\n",
    "            continue\n",
    "\n",
    "        sub = _shapemap.sel(time=t)\n",
    "        box = sub.sel(lat=slice(lat_max, lat_min), lon=slice(lon_min360, lon_max360))\n",
    "\n",
    "        arr = box.data\n",
    "        if not np.isfinite(arr).any():\n",
    "            continue\n",
    "\n",
    "        lat_vals = box.lat.values\n",
    "        lon_vals = box.lon.values\n",
    "        mask = np.isfinite(arr)\n",
    "\n",
    "        for i, j in zip(*np.where(mask)):\n",
    "            lat = float(lat_vals[i])\n",
    "            lon = float(lon_vals[j])\n",
    "            lon_deg = lon if lon <= 180 else lon - 360\n",
    "            point = Point(lon_deg, lat)\n",
    "            match = states_gdf[states_gdf.contains(point)]\n",
    "\n",
    "            if not match.empty:\n",
    "                state_name = match.iloc[0][\"NAME_1\"]\n",
    "                if state_name == \"Uttarakhand\":\n",
    "                    state_events.append(dt)\n",
    "\n",
    "    return state_events\n",
    "\n",
    "\n",
    "def compute_event_durations(times):\n",
    "    times_sorted = sorted(pd.to_datetime(times))\n",
    "    durations = []\n",
    "\n",
    "    if not times_sorted:\n",
    "        return durations\n",
    "\n",
    "    current_start = times_sorted[0]\n",
    "    prev = current_start\n",
    "    hours = 6\n",
    "\n",
    "    for t in times_sorted[1:]:\n",
    "        delta = (t - prev).total_seconds() / 3600\n",
    "        if delta == 6:\n",
    "            hours += 6\n",
    "        else:\n",
    "            if hours >= 12 and hours <= 72:\n",
    "                durations.append((current_start, hours))\n",
    "            current_start = t\n",
    "            hours = 6\n",
    "        prev = t\n",
    "\n",
    "    if hours >= 12 and hours <= 72:\n",
    "        durations.append((current_start, hours))\n",
    "\n",
    "    return durations\n",
    "\n",
    "def classify_ar_category(ivt_val):\n",
    "    if ivt_val < 250:\n",
    "        return None  # Not AR\n",
    "    elif ivt_val < 500:\n",
    "        return \"Weak\"\n",
    "    elif ivt_val < 750:\n",
    "        return \"Moderate\"\n",
    "    elif ivt_val < 1000:\n",
    "        return \"Strong\"\n",
    "    elif ivt_val < 1250:\n",
    "        return \"Extreme\"\n",
    "    else:\n",
    "        return \"Exceptional\"\n",
    "# Parameters\n",
    "start_date = pd.to_datetime(\"2013-06-16 00:00\")\n",
    "end_date = pd.to_datetime(\"2013-06-17 23:59\")\n",
    "\n",
    "# Run for Uttarakhand\n",
    "uttarakhand_events = ar_events_uttarakhand_only(start_date, end_date)\n",
    "uttarakhand_durations = compute_event_durations(uttarakhand_events)\n",
    "\n",
    "# Print summary\n",
    "print(f\"üóª Uttarakhand: {len(uttarakhand_durations)} AR duration events\")\n",
    "for (start, dur) in uttarakhand_durations:\n",
    "    print(f\"   - Start: {start.strftime('%Y-%m-%d %H:%M')} | Duration: {dur} hrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0efe85e7-0f5c-45f0-aaad-7978b5a5711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for AR events in Uttarakhand from 2013-06-16 00:00:00 to 2013-06-17 23:59:00...\n",
      "\n",
      "--- AR Event Categories in Uttarakhand (2013-06-16 to 2013-06-17) ---\n",
      "üóª Uttarakhand: 4 AR duration events found.\n",
      "    - Start: 2013-06-16 00:00  Duration: 12 hrs  Category: Exceptional\n",
      "    - Start: 2013-06-16 06:00  Duration: 12 hrs  Category: Exceptional\n",
      "    - Start: 2013-06-16 12:00  Duration: 12 hrs  Category: Exceptional\n",
      "    - Start: 2013-06-17 12:00  Duration: 12 hrs  Category: Exceptional\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your Indian states shapefile\n",
    "INDIA_STATES_SHAPEFILE = \"india_states.shp\" \n",
    "# Path to your global AR catalog NetCDF file\n",
    "AR_CATALOG_NCFILE = \"globalARcatalog_ERA5_1940-2024_v4.0.nc\"\n",
    "\n",
    "# Parameters for the AR event search\n",
    "START_DATE = pd.to_datetime(\"2013-06-16 00:00\")\n",
    "END_DATE = pd.to_datetime(\"2013-06-17 23:59\")\n",
    "\n",
    "# Define the bounding box for India/Uttarakhand (approximate, adjust if needed)\n",
    "LAT_MIN, LAT_MAX = 6.0, 37.0\n",
    "LON_MIN, LON_MAX = 68.0, 97.5\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    states_gdf = gpd.read_file(INDIA_STATES_SHAPEFILE, layer=\"gadm41_IND_1\")\n",
    "    states_gdf = states_gdf.to_crs(\"EPSG:4326\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "    print(\"Please ensure 'india_states.shp' and its related files (like .dbf, .shx) are in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    _ds = xr.open_dataset(AR_CATALOG_NCFILE, engine=\"netcdf4\")\n",
    "    # No need to squeeze shapemap or ivt_begin/end globally here.\n",
    "    # We will select from _ds directly within the loop.\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: NetCDF file '{AR_CATALOG_NCFILE}' not found.\")\n",
    "    print(\"Please ensure the AR catalog file is in the same directory.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected variable in NetCDF file: {e}\")\n",
    "    print(\"Ensure 'shapemap' and 'tivt' (or 'ivtx'/'ivty') variables exist.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NetCDF dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Functions ---\n",
    "\n",
    "def classify_ar_category(ivt_val):\n",
    "   \n",
    "    if ivt_val <= 250:\n",
    "        return None  # Not AR, or below the \"Weak\" threshold\n",
    "    elif ivt_val > 250 and ivt_value <= 500:\n",
    "        return \"Weak\"\n",
    "    elif ivt_val > 500 and ivt_value <= 750:\n",
    "        return \"Moderate\"\n",
    "    elif ivt_value > 750 and ivt_val <= 1000:\n",
    "        return \"Strong\"\n",
    "    elif ivt_value > 1000 and ivt_val <= 1250:\n",
    "        return \"Extreme\"\n",
    "    else:\n",
    "        return \"Exceptional\"\n",
    "\n",
    "def ar_events_uttarakhand_only(start_date, end_date):\n",
    "    \n",
    "    lon_min360, lon_max360 = LON_MIN % 360, LON_MAX % 360\n",
    "    state_events = []\n",
    "\n",
    "    # Get the time values from the dataset's 'time' coordinate\n",
    "    for t_val in _ds.time.values: \n",
    "        dt = pd.to_datetime(str(t_val))\n",
    "\n",
    "        # Filter by date range\n",
    "        if not (start_date <= dt <= end_date):\n",
    "            continue\n",
    "\n",
    "        # Select the data for the current time from the entire dataset _ds\n",
    "        # This ensures 'time' is available for selection across all variables\n",
    "        ds_at_time = _ds.sel(time=dt, method='nearest')\n",
    "\n",
    "        # Now extract the specific variables from the time-selected dataset\n",
    "        # and squeeze ens/lev if they are singletons\n",
    "        # Use 'tivt' for classification\n",
    "        sub_shapemap = ds_at_time[\"shapemap\"].squeeze(drop=True)\n",
    "        sub_tivt = ds_at_time[\"tivt\"].squeeze(drop=True) \n",
    "\n",
    "        # Ensure that after squeezing, we still have lat and lon dimensions for shapemap\n",
    "        if 'lat' not in sub_shapemap.dims or 'lon' not in sub_shapemap.dims:\n",
    "            print(f\"Warning: shapemap at {dt} does not have 'lat'/'lon' dimensions after squeeze. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "       \n",
    "        box_shapemap = sub_shapemap.sel(lat=slice(LAT_MAX, LAT_MIN), lon=slice(lon_min360, lon_max360))\n",
    "        arr_shapemap = box_shapemap.data\n",
    "\n",
    "        # Skip if no finite AR values in the box for this timestep\n",
    "        if not np.isfinite(arr_shapemap).any():\n",
    "            continue\n",
    "\n",
    "        lat_vals = box_shapemap.lat.values\n",
    "        lon_vals = box_shapemap.lon.values\n",
    "\n",
    "        # Find points where AR is detected (finite values in shapemap)\n",
    "        mask = np.isfinite(arr_shapemap)\n",
    "        for i, j in zip(*np.where(mask)):\n",
    "            lat = float(lat_vals[i])\n",
    "            lon = float(lon_vals[j])\n",
    "            \n",
    "            # Convert longitude to -180 to 180 range for GeoPandas (if necessary)\n",
    "            lon_deg = lon if lon <= 180 else lon - 360\n",
    "            point = Point(lon_deg, lat)\n",
    "\n",
    "            # Check if the point falls within any Indian state, then specifically Uttarakhand\n",
    "            match = states_gdf[states_gdf.contains(point)]\n",
    "            if not match.empty:\n",
    "                state_name = match.iloc[0][\"NAME_1\"]\n",
    "                if state_name == \"Uttarakhand\":\n",
    "                    # Get the 'tivt' value for the closest latitude.\n",
    "                    # Since tivt is (lat), we select only by lat.\n",
    "                    try:\n",
    "                        ivt_val = sub_tivt.sel(lat=lat, method='nearest').item() \n",
    "                    except KeyError:\n",
    "                        print(f\"Error: Could not select TIVT at lat={lat} for time {dt}. Skipping point.\")\n",
    "                        continue # Skip this point if TIVT selection fails\n",
    "                    \n",
    "                    ar_category = classify_ar_category(ivt_val)\n",
    "                    if ar_category: # Only append if it's classified as an AR category\n",
    "                        state_events.append((dt, ar_category))\n",
    "    return state_events\n",
    "\n",
    "def compute_event_durations(times_with_category):\n",
    "   \n",
    "    # Sort events primarily by time\n",
    "    times_sorted = sorted(times_with_category, key=lambda x: x[0])\n",
    "    durations = []\n",
    "\n",
    "    if not times_sorted:\n",
    "        return durations\n",
    "\n",
    "    current_start_time, current_start_category = times_sorted[0]\n",
    "    prev_time = current_start_time\n",
    "    hours = 6  # Each time step is 6 hours in your data\n",
    "\n",
    "    for t, category in times_sorted[1:]:\n",
    "        delta = (t - prev_time).total_seconds() / 3600  # Calculate time difference in hours\n",
    "\n",
    "        if delta == 6:\n",
    "            hours += 6\n",
    "        else:\n",
    "            # End of a continuous event, check duration\n",
    "            if 12 <= hours <= 72:\n",
    "                durations.append((current_start_time, hours, current_start_category))\n",
    "            \n",
    "            # Start a new event\n",
    "            current_start_time = t\n",
    "            current_start_category = category\n",
    "            hours = 6\n",
    "        prev_time = t\n",
    "\n",
    "    # Add the last event if its duration meets the criteria\n",
    "    if 12 <= hours <= 72:\n",
    "        durations.append((current_start_time, hours, current_start_category))\n",
    "\n",
    "    return durations\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Searching for AR events in Uttarakhand from {START_DATE} to {END_DATE}...\")\n",
    "    \n",
    "    uttarakhand_events = ar_events_uttarakhand_only(START_DATE, END_DATE)\n",
    "    uttarakhand_durations = compute_event_durations(uttarakhand_events)\n",
    "\n",
    "    print(f\"\\n--- AR Event Categories in Uttarakhand ({START_DATE.strftime('%Y-%m-%d')} to {END_DATE.strftime('%Y-%m-%d')}) ---\")\n",
    "    if uttarakhand_durations:\n",
    "        print(f\"üóª Uttarakhand: {len(uttarakhand_durations)} AR duration events found.\")\n",
    "        for (start, dur, category) in uttarakhand_durations:\n",
    "            print(f\"    - Start: {start.strftime('%Y-%m-%d %H:%M')}  Duration: {dur} hrs  Category: {category}\")\n",
    "    else:\n",
    "        print(\"No AR duration events (12-72 hours) found in Uttarakhand for the specified period.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0592bd-f4b7-4b86-a9f7-b5104d3c2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------2000-2005---------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb410a42-c996-427b-9bbe-0e751aa34c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for AR events in Uttarakhand from 2000-01-01 00:00:00 to 2005-12-31 23:59:00...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 169\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching for AR events in Uttarakhand from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m     uttarakhand_events \u001b[38;5;241m=\u001b[39m ar_events_uttarakhand_only(START_DATE, END_DATE)\n\u001b[0;32m    170\u001b[0m     uttarakhand_durations \u001b[38;5;241m=\u001b[39m compute_event_durations(uttarakhand_events)\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- AR Event Categories in Uttarakhand (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART_DATE\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND_DATE\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 110\u001b[0m, in \u001b[0;36mar_events_uttarakhand_only\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Convert longitude to -180 to 180 range for GeoPandas (if necessary)\u001b[39;00m\n\u001b[0;32m    109\u001b[0m lon_deg \u001b[38;5;241m=\u001b[39m lon \u001b[38;5;28;01mif\u001b[39;00m lon \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m lon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m360\u001b[39m\n\u001b[1;32m--> 110\u001b[0m point \u001b[38;5;241m=\u001b[39m Point(lon_deg, lat)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Check if the point falls within any Indian state, then specifically Uttarakhand\u001b[39;00m\n\u001b[0;32m    113\u001b[0m match \u001b[38;5;241m=\u001b[39m states_gdf[states_gdf\u001b[38;5;241m.\u001b[39mcontains(point)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\shapely\\geometry\\point.py:81\u001b[0m, in \u001b[0;36mPoint.__new__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(coords\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mnumber):\n\u001b[0;32m     80\u001b[0m     coords \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m coords]\n\u001b[1;32m---> 81\u001b[0m geom \u001b[38;5;241m=\u001b[39m shapely\u001b[38;5;241m.\u001b[39mpoints(coords)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(geom, Point):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid values passed to Point constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\shapely\\decorators.py:173\u001b[0m, in \u001b[0;36mdeprecate_positional.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 173\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    175\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args)\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m warn_from:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\shapely\\decorators.py:88\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     87\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\shapely\\creation.py:124\u001b[0m, in \u001b[0;36mpoints\u001b[1;34m(coords, y, z, indices, handle_nan, out, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m     handle_nan \u001b[38;5;241m=\u001b[39m HandleNaN\u001b[38;5;241m.\u001b[39mget_value(handle_nan)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mpoints(coords, np\u001b[38;5;241m.\u001b[39mintc(handle_nan), out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simple_geometries_1d(\n\u001b[0;32m    127\u001b[0m         coords, indices, GeometryType\u001b[38;5;241m.\u001b[39mPOINT, handle_nan\u001b[38;5;241m=\u001b[39mhandle_nan, out\u001b[38;5;241m=\u001b[39mout\n\u001b[0;32m    128\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your Indian states shapefile\n",
    "INDIA_STATES_SHAPEFILE = \"india_states.shp\" \n",
    "# Path to your global AR catalog NetCDF file\n",
    "AR_CATALOG_NCFILE = \"globalARcatalog_ERA5_1940-2024_v4.0.nc\"\n",
    "\n",
    "# Parameters for the AR event search\n",
    "START_DATE = pd.to_datetime(\"2000-01-01 00:00\")\n",
    "END_DATE = pd.to_datetime(\"2005-12-31 23:59\")\n",
    "\n",
    "# Define the bounding box for India/Uttarakhand (approximate, adjust if needed)\n",
    "LAT_MIN, LAT_MAX = 6.0, 37.0\n",
    "LON_MIN, LON_MAX = 68.0, 97.5\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    states_gdf = gpd.read_file(INDIA_STATES_SHAPEFILE, layer=\"gadm41_IND_1\")\n",
    "    states_gdf = states_gdf.to_crs(\"EPSG:4326\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "    print(\"Please ensure 'india_states.shp' and its related files (like .dbf, .shx) are in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    _ds = xr.open_dataset(AR_CATALOG_NCFILE, engine=\"netcdf4\")\n",
    "    # No need to squeeze shapemap or ivt_begin/end globally here.\n",
    "    # We will select from _ds directly within the loop.\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: NetCDF file '{AR_CATALOG_NCFILE}' not found.\")\n",
    "    print(\"Please ensure the AR catalog file is in the same directory.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected variable in NetCDF file: {e}\")\n",
    "    print(\"Ensure 'shapemap' and 'tivt' (or 'ivtx'/'ivty') variables exist.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NetCDF dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Functions ---\n",
    "\n",
    "def classify_ar_category(ivt_val):\n",
    "    if ivt_val <= 250:\n",
    "        return None  # Not AR, or below the \"Weak\" threshold\n",
    "    elif ivt_val > 250 and ivt_val <= 500:\n",
    "        return \"Weak\"\n",
    "    elif ivt_val > 500 and ivt_val <= 750:\n",
    "        return \"Moderate\"\n",
    "    elif ivt_val > 750 and ivt_val <= 1000:\n",
    "        return \"Strong\"\n",
    "    elif ivt_val > 1000 and ivt_val <= 1250:\n",
    "        return \"Extreme\"\n",
    "    else:\n",
    "        return \"Exceptional\"\n",
    "\n",
    "\n",
    "def ar_events_uttarakhand_only(start_date, end_date):\n",
    "    \n",
    "    lon_min360, lon_max360 = LON_MIN % 360, LON_MAX % 360\n",
    "    state_events = []\n",
    "\n",
    "    # Get the time values from the dataset's 'time' coordinate\n",
    "    for t_val in _ds.time.values: \n",
    "        dt = pd.to_datetime(str(t_val))\n",
    "\n",
    "        # Filter by date range\n",
    "        if not (start_date <= dt <= end_date):\n",
    "            continue\n",
    "\n",
    "        # Select the data for the current time from the entire dataset _ds\n",
    "        # This ensures 'time' is available for selection across all variables\n",
    "        ds_at_time = _ds.sel(time=dt, method='nearest')\n",
    "\n",
    "        # Now extract the specific variables from the time-selected dataset\n",
    "        # and squeeze ens/lev if they are singletons\n",
    "        # Use 'tivt' for classification\n",
    "        sub_shapemap = ds_at_time[\"shapemap\"].squeeze(drop=True)\n",
    "        sub_tivt = ds_at_time[\"tivt\"].squeeze(drop=True) \n",
    "\n",
    "        # Ensure that after squeezing, we still have lat and lon dimensions for shapemap\n",
    "        if 'lat' not in sub_shapemap.dims or 'lon' not in sub_shapemap.dims:\n",
    "            print(f\"Warning: shapemap at {dt} does not have 'lat'/'lon' dimensions after squeeze. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "       \n",
    "        box_shapemap = sub_shapemap.sel(lat=slice(LAT_MAX, LAT_MIN), lon=slice(lon_min360, lon_max360))\n",
    "        arr_shapemap = box_shapemap.data\n",
    "\n",
    "        # Skip if no finite AR values in the box for this timestep\n",
    "        if not np.isfinite(arr_shapemap).any():\n",
    "            continue\n",
    "\n",
    "        lat_vals = box_shapemap.lat.values\n",
    "        lon_vals = box_shapemap.lon.values\n",
    "\n",
    "        # Find points where AR is detected (finite values in shapemap)\n",
    "        mask = np.isfinite(arr_shapemap)\n",
    "        for i, j in zip(*np.where(mask)):\n",
    "            lat = float(lat_vals[i])\n",
    "            lon = float(lon_vals[j])\n",
    "            \n",
    "            # Convert longitude to -180 to 180 range for GeoPandas (if necessary)\n",
    "            lon_deg = lon if lon <= 180 else lon - 360\n",
    "            point = Point(lon_deg, lat)\n",
    "\n",
    "            # Check if the point falls within any Indian state, then specifically Uttarakhand\n",
    "            match = states_gdf[states_gdf.contains(point)]\n",
    "            if not match.empty:\n",
    "                state_name = match.iloc[0][\"NAME_1\"]\n",
    "                if state_name == \"Uttarakhand\":\n",
    "                    # Get the 'tivt' value for the closest latitude.\n",
    "                    # Since tivt is (lat), we select only by lat.\n",
    "                    try:\n",
    "                        ivt_val = sub_tivt.sel(lat=lat, method='nearest').item() \n",
    "                    except KeyError:\n",
    "                        print(f\"Error: Could not select TIVT at lat={lat} for time {dt}. Skipping point.\")\n",
    "                        continue # Skip this point if TIVT selection fails\n",
    "                    \n",
    "                    ar_category = classify_ar_category(ivt_val)\n",
    "                    if ar_category: # Only append if it's classified as an AR category\n",
    "                        state_events.append((dt, ar_category))\n",
    "    return state_events\n",
    "\n",
    "def compute_event_durations(times_with_category):\n",
    "   \n",
    "    # Sort events primarily by time\n",
    "    times_sorted = sorted(times_with_category, key=lambda x: x[0])\n",
    "    durations = []\n",
    "\n",
    "    if not times_sorted:\n",
    "        return durations\n",
    "\n",
    "    current_start_time, current_start_category = times_sorted[0]\n",
    "    prev_time = current_start_time\n",
    "    hours = 6  # Each time step is 6 hours in your data\n",
    "\n",
    "    for t, category in times_sorted[1:]:\n",
    "        delta = (t - prev_time).total_seconds() / 3600  # Calculate time difference in hours\n",
    "\n",
    "        if delta == 6:\n",
    "            hours += 6\n",
    "        else:\n",
    "            # End of a continuous event, check duration\n",
    "            if 12 <= hours <= 72:\n",
    "                durations.append((current_start_time, hours, current_start_category))\n",
    "            \n",
    "            # Start a new event\n",
    "            current_start_time = t\n",
    "            current_start_category = category\n",
    "            hours = 6\n",
    "        prev_time = t\n",
    "\n",
    "    # Add the last event if its duration meets the criteria\n",
    "    if 12 <= hours <= 72:\n",
    "        durations.append((current_start_time, hours, current_start_category))\n",
    "\n",
    "    return durations\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Searching for AR events in Uttarakhand from {START_DATE} to {END_DATE}...\")\n",
    "    \n",
    "    uttarakhand_events = ar_events_uttarakhand_only(START_DATE, END_DATE)\n",
    "    uttarakhand_durations = compute_event_durations(uttarakhand_events)\n",
    "\n",
    "    print(f\"\\n--- AR Event Categories in Uttarakhand ({START_DATE.strftime('%Y-%m-%d')} to {END_DATE.strftime('%Y-%m-%d')}) ---\")\n",
    "    if uttarakhand_durations:\n",
    "        print(f\"üóª Uttarakhand: {len(uttarakhand_durations)} AR duration events found.\")\n",
    "        for (start, dur, category) in uttarakhand_durations:\n",
    "            print(f\"    - Start: {start.strftime('%Y-%m-%d %H:%M')}  Duration: {dur} hrs  Category: {category}\")\n",
    "    else:\n",
    "        print(\"No AR duration events (12-72 hours) found in Uttarakhand for the specified period.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904028a-d128-488f-b4a7-101862843770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iris)",
   "language": "python",
   "name": "iris_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
